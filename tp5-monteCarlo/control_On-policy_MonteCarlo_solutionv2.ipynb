{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo On policy\n",
    "## Sources \n",
    "- Reinforcement Learning : An Introduction, by Richard Sutton and Andrew Barto\n",
    "\n",
    "Toujours basé sur le Blackjack, nous allons rechercher une politique optimum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création de l'environnement Blackjack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Blackjack-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionnaire pour stocker les Q values (action-valeur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = defaultdict(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionnaire pour le total des retours G poour chaque couple s,a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_return = defaultdict(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionnaire pour le cumul du nombre de passage pour tout les s,a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = defaultdict(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définissons une politique epsilon-greedy\n",
    "Paramètres d'entrés   \n",
    "    - Q fonction (s,a)   \n",
    "    - L'état courant   \n",
    "    - epsilon   \n",
    " \n",
    "Paramètre de sortie    \n",
    "    - a action choisie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(state,Q,epsilon):\n",
    "  \n",
    "    if random.uniform(0,1) < epsilon:\n",
    "        return env.action_space.sample() # exploration\n",
    "    else:\n",
    "        max_q=-1\n",
    "        max_a=0\n",
    "        for a in range(env.action_space.n):\n",
    "            if (state,a) in Q:\n",
    "                if Q[(state,a)] > max_q:\n",
    "                    max_q=Q[(state,a)]\n",
    "                    max_a=a\n",
    "        return(max_a)\n",
    "        # return max(list(range(env.action_space.n)), key = lambda x: Q[(state,x)]) # exploitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating an episode\n",
    "\n",
    "Now, let's generate an episode using the epsilon-greedy policy. We define a function called\n",
    "`generate_episode` which takes the Q value as an input and returns the episode.\n",
    "\n",
    "First, let's set the number of time steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Générateur d'épisode\n",
    "Entrée :\n",
    "- Q fonction\n",
    "- espilon pour notre politique aléatoire\n",
    "\n",
    "Sortie :\n",
    "- notre épisode sous la forma s,a ,s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_timesteps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_episode(Q,epsilon):\n",
    "    \n",
    "    episode = []\n",
    "    \n",
    "    state = env.reset()[0]\n",
    "    \n",
    "    for t in range(num_timesteps):\n",
    "        \n",
    "        # Sélection d'une action en fonction de notre politique\n",
    "        action = epsilon_greedy_policy(state,Q,espilon)\n",
    "        \n",
    "        # envoie de l'action à l'environnement pour retour (s_, r, done)\n",
    "        next_state, reward, done, truncated, info = env.step(action)\n",
    "        \n",
    "        # stockage dans la liste du triplet (état, action, récompense)\n",
    "        episode.append((state, action, reward))\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "            \n",
    "        state = next_state\n",
    "\n",
    "    return episode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Calcul de la politique optimale\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 50000\n",
    "espilon = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons initialiser une politique random au démarrage.      \n",
    "Selon le modèle GPI, Notre Q fonction va tendre vers l'optimale et donc notre politique également.<br>\n",
    "Pour simplifier et parce que l'intéret est limité dans le cas du blackjack, nous ferons abstraction de gamma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "for i in range(num_iterations):\n",
    "    \n",
    "    # on génére un épisode\n",
    "    episode = generate_episode(Q,espilon)\n",
    "    \n",
    "    # on stocker les pairs s,a de l'épisode\n",
    "    all_state_action_pairs = [(s, a) for (s,a,r) in episode]\n",
    "    \n",
    "    # on stocke les récompense\n",
    "    rewards = [r for (s,a,r) in episode]\n",
    "\n",
    "    # Pour chaque t de l'épisode \n",
    "    for t, (state, action, reward) in enumerate(episode):\n",
    "\n",
    "        # First visit : on ne prend en compte que le premier passage s,a\n",
    "        if not (state, action) in all_state_action_pairs[0:t]:\n",
    "            \n",
    "            # Calcul de G avec y = 1\n",
    "            R = sum(rewards[t:])\n",
    "            \n",
    "            # Cumul G\n",
    "            total_return[(state,action)] = total_return[(state,action)] + R\n",
    "            \n",
    "            # Comptage du nombre de passage\n",
    "            N[(state, action)] += 1\n",
    "\n",
    "            # Calcul de Q value (s,a) par la moyenne des G cumulés sur N\n",
    "            Q[(state,action)] = total_return[(state, action)] / N[(state, action)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8891170431211499"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q[((20,10,0),1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45368620037807184"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q[((20,10,0),0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stockage du résultat dans un Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(Q.items(),columns=['state_action pair','value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_action pair</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>((20, 10, 0), 0)</td>\n",
       "      <td>0.453686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>((12, 1, 0), 0)</td>\n",
       "      <td>-0.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>((12, 10, 0), 0)</td>\n",
       "      <td>-0.602899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>((16, 9, 0), 0)</td>\n",
       "      <td>-0.655738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>((14, 3, 0), 0)</td>\n",
       "      <td>-0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>((18, 10, 0), 0)</td>\n",
       "      <td>-0.284921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>((9, 2, 0), 0)</td>\n",
       "      <td>-0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>((18, 7, 0), 0)</td>\n",
       "      <td>0.347639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>((20, 8, 0), 1)</td>\n",
       "      <td>-0.883212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>((19, 10, 0), 0)</td>\n",
       "      <td>0.011044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>((20, 5, 0), 0)</td>\n",
       "      <td>0.695531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state_action pair     value\n",
       "0   ((20, 10, 0), 0)  0.453686\n",
       "1    ((12, 1, 0), 0) -0.764706\n",
       "2   ((12, 10, 0), 0) -0.602899\n",
       "3    ((16, 9, 0), 0) -0.655738\n",
       "4    ((14, 3, 0), 0) -0.250000\n",
       "5   ((18, 10, 0), 0) -0.284921\n",
       "6     ((9, 2, 0), 0) -0.333333\n",
       "7    ((18, 7, 0), 0)  0.347639\n",
       "8    ((20, 8, 0), 1) -0.883212\n",
       "9   ((19, 10, 0), 0)  0.011044\n",
       "10   ((20, 5, 0), 0)  0.695531"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons un Q optimal ou proche.   \n",
    "Notre politique est basée sur une approche gloutonne de Q donc elle même optimale !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Exemple\n",
    "J'ai en main 19 points (sans as) et le croupier 5 points visibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_action pair</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>((19, 5, 0), 0)</td>\n",
       "      <td>0.436214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    state_action pair     value\n",
       "244   ((19, 5, 0), 0)  0.436214"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[ df['state_action pair'] == ((19,5,False),0) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_action pair</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>((19, 5, 0), 1)</td>\n",
       "      <td>-0.785714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    state_action pair     value\n",
       "396   ((19, 5, 0), 1) -0.785714"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[ df['state_action pair'] == ((19,5,False),1) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ma politique va donc choisir un stand (0) car la valeur de fonction d'action-état est la plus haute !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl2023",
   "language": "python",
   "name": "rl2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

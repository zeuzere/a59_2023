{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c74f263-ff78-4fe7-b7da-800396652c3b",
   "metadata": {},
   "source": [
    "---\n",
    "# Programmation dynamique\n",
    "\n",
    "\n",
    "Fabrice Mulotti<br>\n",
    "\n",
    "v2 2023\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf16a8fb-cd3a-4b53-bff2-abe3b9a3a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb77d95-fba9-42cd-8fb1-dc715521d2f9",
   "metadata": {},
   "source": [
    "---\n",
    "## Frozen Lake\n",
    "\n",
    "Découvrons notre environnement <br>\n",
    "<br>\n",
    "![ForzenLake](images/frozen_lake.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbf365b-8365-483c-9f43-e82eb4bf4105",
   "metadata": {},
   "source": [
    "https://gymnasium.farama.org/environments/toy_text/frozen_lake/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb7e991f-ecec-4312-b19f-3085de1ee086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# déclaration de l'environnement\n",
    "env = env = gym.make('FrozenLake8x8-v1',is_slippery = False,map_name=\"4x4\", render_mode=\"ansi\") # ,render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60c49269-53b4-4c76-a31e-db228acddafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# affichage\n",
    "env.reset()\n",
    "print(env.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e149943c-56c1-4c63-97ca-6ebb5dff23b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nombre d'états\n",
    "env.observation_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3068a2b9-d0ec-47a6-928d-6979ea1be401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nombre d'actions possibles\n",
    "env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2201db5-cf31-4b14-8322-c679035b546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT=0\n",
    "DOWN=1\n",
    "RIGHT=2\n",
    "UP=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df46dbcb-eec8-47b0-8e4d-59cbd23aaf6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tirage aléatoire de fonction\n",
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6f9572a-9f2a-4e8d-b82c-3d42e357a0f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, {'prob': 1})\n"
     ]
    }
   ],
   "source": [
    "print(env.reset())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5db5e43-a138-44eb-b2aa-0f9a079eedd3",
   "metadata": {},
   "source": [
    "---\n",
    "## action\n",
    "\n",
    "https://gymnasium.farama.org/api/env/#gymnasium.Env.step\n",
    "<br>\n",
    "env.step retourne les infos suivantes :<br>\n",
    "- observation (s')<br>\n",
    "- reward (r)<br>\n",
    "- termination (bool)<br>\n",
    "- truncated (bool)<br>\n",
    "- info <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a3f11bb-866b-4d7d-8832-99213d68b848",
   "metadata": {},
   "outputs": [],
   "source": [
    "r=env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31b65c35-8455-428b-b82c-4784289663b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.0, False, False, {'prob': 1.0})\n"
     ]
    }
   ],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24e263ea-20f4-4a4f-857c-5b6931f30beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récompense 0.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Récompense {r[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f527683d-b629-49ba-a13d-4b4ac60cf866",
   "metadata": {},
   "source": [
    "## Matrice de transition\n",
    "\n",
    "__env.P[etat][action] retourne :__<br>\n",
    "Probabilité<br>\n",
    "s'<br>\n",
    "r<br>\n",
    "état final ? <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1498b2dc-1350-4f8c-ad51-28577c7ee169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(1.0, 4, 0.0, False)],\n",
       " 1: [(1.0, 8, 0.0, False)],\n",
       " 2: [(1.0, 5, 0.0, True)],\n",
       " 3: [(1.0, 0, 0.0, False)]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrice de transition, exemple s=4\n",
    "env.unwrapped.P[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e890f4-c365-4279-afa2-2c28c1261b06",
   "metadata": {},
   "source": [
    "Si le sol n'est pas glissant : <br>\n",
    "1 action => 1 état suivant <br>\n",
    "\n",
    "Si le sol est glissant : <br>\n",
    "3 destinations possibles (33% de prob), dont une en terminaison <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c275aec8-6cd1-424e-88ae-e90a069e1c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupiter2/data/venv/rl2023/lib/python3.9/site-packages/gymnasium/core.py:297: UserWarning: \u001b[33mWARN: env.P to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.P` for environment variables or `env.get_attr('P')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# récompense\n",
    "env.P[4][RIGHT][0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0c5f15c-7feb-48b3-a33d-d09eb5eb8d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prochain état \n",
    "env.P[4][RIGHT][0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff54236-fd50-4e0a-a575-6db80d2dc3b3",
   "metadata": {},
   "source": [
    "---\n",
    "## Test complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89074e4c-c3da-4b52-985f-360f2c67f9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "Action=1, (4, 0.0, False, False, {'prob': 1.0})\n",
      "  (Down)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "Action=3, (0, 0.0, False, False, {'prob': 1.0})\n",
      "  (Up)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "Action=3, (0, 0.0, False, False, {'prob': 1.0})\n",
      "  (Up)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "Action=1, (4, 0.0, False, False, {'prob': 1.0})\n",
      "  (Down)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "Action=2, (5, 0.0, True, False, {'prob': 1.0})\n",
      "  (Right)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# S: initial state\n",
    "# F: frozen lake\n",
    "# H: hole\n",
    "# G: the goal\n",
    "\n",
    "env.reset()\n",
    "fin=False\n",
    "print(env.render())\n",
    "c=0\n",
    "while not fin:\n",
    "    action=env.action_space.sample()\n",
    "    r=env.step(action)\n",
    "    print(f\"Action={action}, {r}\")\n",
    "    fin = r[2] or r[3]\n",
    "    time.sleep(0.5)\n",
    "    print(env.render())\n",
    "    c+=1\n",
    "    if c==10:\n",
    "        fin=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20beaf94-a65d-48c5-aff9-f492646cd27c",
   "metadata": {},
   "source": [
    "---\n",
    "# Itération sur politique\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b4bbe2-ce45-4834-9a1c-3f76a18821fc",
   "metadata": {},
   "source": [
    "![Politique](images/politique.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b991918-956d-47aa-b804-b4a24ca78279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1.0\n",
      "0\n",
      "0.8\n",
      "0\n",
      "0.6400000000000001\n",
      "0\n",
      "0.5120000000000001\n",
      "0\n",
      "0.40960000000000013\n",
      "0\n",
      "0.32768000000000014\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "theta = 0.005 # Notre limite de convergence\n",
    "gamma = 0.8 # dépréciation du futur\n",
    "\n",
    "V = np.zeros((env.observation_space.n)) # initialisation fonction de valeur\n",
    "Policy = np.zeros((env.observation_space.n)) # initialisation d'une politique\n",
    "\n",
    "loopCounter=0\n",
    "while True:\n",
    "    # Policy evaluation -----------------------------------\n",
    "    while True:\n",
    "        delta = 0\n",
    "        loopCounter+=1\n",
    "        for s in range(env.observation_space.n):\n",
    "            v = V[s]\n",
    "            action = Policy[s]\n",
    "            q=0\n",
    "            for destination in env.P[s][action]:\n",
    "                probabilite=destination[0]\n",
    "                s_prime=destination[1]\n",
    "                recompense=destination[2]\n",
    "                q+=probabilite*(recompense+gamma*V[s_prime])\n",
    "            V[s]=q\n",
    "            delta = max(delta,np.abs(v-V[s]))\n",
    "        print(delta)\n",
    "        if delta < theta:\n",
    "            break;\n",
    "\n",
    "    # Policy improvement --------------------------------\n",
    "    policy_stable=True\n",
    "    for s in range(env.observation_space.n):\n",
    "        old_action=Policy[s]\n",
    "        Q=[]\n",
    "        for a in range(env.action_space.n):\n",
    "            q=0\n",
    "            for destination in env.P[s][a]:\n",
    "                probabilite=destination[0]\n",
    "                s_prime=destination[1]\n",
    "                recompense=destination[2]\n",
    "                q+=probabilite*(recompense+gamma*V[s_prime])\n",
    "            Q.append(q)\n",
    "        new_action=np.argmax(Q)\n",
    "        if new_action!=old_action:\n",
    "            policy_stable=False\n",
    "            Policy[s]=new_action\n",
    "    if policy_stable==True:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b74aebe-a7c9-4fa0-a800-7492e8b2a328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loopCounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de19d4e3-1c35-4bb5-b8df-29fa8ff78712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [2., 1., 1., 0.],\n",
       "       [0., 2., 2., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Policy.reshape(4,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb7e827-58b8-460e-8169-0aeb1be891f4",
   "metadata": {},
   "source": [
    "![ForzenLake](images/frozen_lake.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6df52ba-29af-412e-b5ce-5de420e2e46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00997014, 0.01244529, 0.02606749, 0.01445414],\n",
       "       [0.02067014, 0.        , 0.05871582, 0.        ],\n",
       "       [0.05304812, 0.13062298, 0.19511969, 0.        ],\n",
       "       [0.        , 0.24417446, 0.54307587, 0.        ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V.reshape(4,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba45972-cca4-4c33-aa6c-f1d673cae3d3",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "slippery = False , deterministe<br>\n",
    "slippery = True , stocastique, choix des actions évitant le risque<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f456d9d6-4ee8-435a-a72f-3d39c3ff5669",
   "metadata": {},
   "source": [
    "---\n",
    "# Itération sur valeurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e41b6d4-1758-49b7-85be-130da3d446ae",
   "metadata": {},
   "source": [
    "![Valeur](images/iteration_valeur.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc34da9f-4b5e-4d11-b5b9-daf02f3a5305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.8\n",
      "0.6400000000000001\n",
      "0.5120000000000001\n",
      "0.40960000000000013\n",
      "0.32768000000000014\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "theta = 0.005 # Notre limite de convergence\n",
    "gamma = 0.8 # dépréciation du futur\n",
    "\n",
    "V = np.zeros((env.observation_space.n)) # initialisation fonction de valeur\n",
    "Policy = np.zeros((env.observation_space.n)) # initialisation d'une politique\n",
    "\n",
    "# Update value function -----------------------------------\n",
    "while True:\n",
    "        delta = 0\n",
    "        loopCounter+=1\n",
    "        for s in range(env.observation_space.n):\n",
    "            v = V[s]\n",
    "            qmax=0\n",
    "            for action in range(env.action_space.n): # avant  Policy[s]\n",
    "                q=0\n",
    "                for destination in env.P[s][action]:\n",
    "                    probabilite=destination[0]\n",
    "                    s_prime=destination[1]\n",
    "                    recompense=destination[2]\n",
    "                    q+=probabilite*(recompense+gamma*V[s_prime])\n",
    "                qmax=max(qmax,q)\n",
    "                \n",
    "            V[s]=qmax\n",
    "            delta = max(delta,np.abs(v-V[s]))\n",
    "        print(delta)\n",
    "        if delta < theta:\n",
    "            break;\n",
    "\n",
    "            \n",
    "# Policy  --------------------------------\n",
    "for s in range(env.observation_space.n):\n",
    "    Q=[]\n",
    "    for a in range(env.action_space.n):\n",
    "        q=0\n",
    "        for destination in env.P[s][a]:\n",
    "            probabilite=destination[0]\n",
    "            s_prime=destination[1]\n",
    "            recompense=destination[2]\n",
    "            q+=probabilite*(recompense+gamma*V[s_prime])\n",
    "        Q.append(q)\n",
    "    Policy[s]=np.argmax(Q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "363d5b01-95d2-4714-9393-35cc35ef5747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [2., 1., 1., 0.],\n",
       "       [0., 2., 2., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Policy.reshape(4,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd8cac4-6efd-4c59-8324-c556c0c2230d",
   "metadata": {},
   "source": [
    "![ForzenLake](images/frozen_lake.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1c0d5778-3a62-4585-9d51-bafa9e27e11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00616192, 0.0087758 , 0.02240322, 0.01076427],\n",
       "       [0.0167648 , 0.        , 0.05667309, 0.        ],\n",
       "       [0.04880346, 0.12684139, 0.19275183, 0.        ],\n",
       "       [0.        , 0.24076724, 0.54135257, 0.        ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V.reshape(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2351a7-bbee-47f4-9697-8983b37b100d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce513eb8-b73e-4048-848d-f06285b87e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl2023",
   "language": "python",
   "name": "rl2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
